{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pyvi import ViTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(text):\n",
    "    # Xóa dữ liệu trùng lặp\n",
    "    text = re.sub(r'\\b(\\w+)(\\s+\\1\\b)+', r'\\1', text, flags=re.IGNORECASE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    # Loại bỏ các thẻ HTML\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_code(text):\n",
    "    # Loại bỏ các thẻ code, mã JavaScript và mã CSS\n",
    "    text = re.sub(r'<script.?>.?</script>', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'<style.?>.?</style>', '', text, flags=re.DOTALL)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    # Loại bỏ các ký tự không mong muốn, nhưng giữ lại \"__label\"\n",
    "    text = re.sub(r'[^\\w\\s:]|(?<!_)_label', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_curly_braces_content(text):\n",
    "    # Loại bỏ nội dung trong các dấu ngoặc nhọn {{...}}\n",
    "    text = re.sub(r'{{.*?}}', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_content(text, inputFileWasReplaced):\n",
    "    text = re.sub(r':', '', text)\n",
    "    text = re.sub(r'content\\s*', '', text, flags=re.DOTALL)\n",
    "    text = re.sub(r'^_label__', '__label__', text)\n",
    "    text = re.sub(rf'__label__{inputFileWasReplaced}_', f'__label__{inputFileWasReplaced} ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_startswith_or_endswith_underscore_except_label(text, inputFileWasReplaced):\n",
    "    words = text.split()\n",
    "    updated_words = []\n",
    "    for word in words:\n",
    "        if word.startswith('_') and word != '__label__' + inputFileWasReplaced:\n",
    "            word = word[1:]\n",
    "        if word.endswith('_'):\n",
    "            word = word[:-1]\n",
    "        updated_words.append(word)\n",
    "    return ' '.join(updated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(output_file_path, inputFileWasReplaced):\n",
    "    tonghop_directory = 'tonghop'\n",
    "    if not os.path.exists(tonghop_directory):\n",
    "        os.makedirs(tonghop_directory)\n",
    "    filetonghop = os.path.join(tonghop_directory, 'tonghop_' + inputFileWasReplaced + '.txt')\n",
    "    with open('stopwords.txt', 'r', encoding='utf-8') as stop_file:\n",
    "        stopwords = set(stop_file.read().splitlines())\n",
    "\n",
    "    with open(output_file_path, 'r', encoding='utf-8') as input_file, open(filetonghop, 'w', encoding='utf-8') as output_file:\n",
    "        for line in input_file:\n",
    "            # tách các từ trong dòng và kiểm tra xem chúng có trong stopwords không\n",
    "            words = line.split()\n",
    "            words = [word for word in words if word.lower() not in stopwords]\n",
    "\n",
    "            # ghi vào file mới content đã được loại bỏ từ stopwords vào tệp tonghop2\n",
    "            output_file.write(' '.join(words) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddicchar():\n",
    "    dic = {}\n",
    "    char1252 = 'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ'.split(\n",
    "        '|')\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        '|')\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    "dicchar = loaddicchar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_unicode(txt):\n",
    "    return re.sub(\n",
    "        r'à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ',\n",
    "        lambda x: dicchar[x.group()], txt)\n",
    "\n",
    "bang_nguyen_am = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
    "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
    "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
    "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
    "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
    "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
    "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
    "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
    "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
    "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
    "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
    "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
    "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
    "\n",
    "nguyen_am_to_ids = {}\n",
    "\n",
    "for i in range(len(bang_nguyen_am)):\n",
    "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
    "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_vietnam_word(word):\n",
    "    chars = list(word)\n",
    "    nguyen_am_index = -1\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x != -1:\n",
    "            if nguyen_am_index == -1:\n",
    "                nguyen_am_index = index\n",
    "            else:\n",
    "                if index - nguyen_am_index != 1:\n",
    "                    return False\n",
    "                nguyen_am_index = index\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chuan_hoa_dau_tu_tieng_viet(word):\n",
    "    if not is_valid_vietnam_word(word):\n",
    "        return word\n",
    "\n",
    "    chars = list(word)\n",
    "    dau_cau = 0\n",
    "    nguyen_am_index = []\n",
    "    qu_or_gi = False\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x == -1:\n",
    "            continue\n",
    "        elif x == 9:  # check qu\n",
    "            if index != 0 and chars[index - 1] == 'q':\n",
    "                chars[index] = 'u'\n",
    "                qu_or_gi = True\n",
    "        elif x == 5:  # check gi\n",
    "            if index != 0 and chars[index - 1] == 'g':\n",
    "                chars[index] = 'i'\n",
    "                qu_or_gi = True\n",
    "        if y != 0:\n",
    "            dau_cau = y\n",
    "            chars[index] = bang_nguyen_am[x][0]\n",
    "        if not qu_or_gi or index != 1:\n",
    "            nguyen_am_index.append(index)\n",
    "    if len(nguyen_am_index) < 2:\n",
    "        if qu_or_gi:\n",
    "            if len(chars) == 2:\n",
    "                x, y = nguyen_am_to_ids.get(chars[1])\n",
    "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
    "            else:\n",
    "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
    "                if x != -1:\n",
    "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
    "                else:\n",
    "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
    "            return ''.join(chars)\n",
    "        return word\n",
    "\n",
    "    for index in nguyen_am_index:\n",
    "        x, y = nguyen_am_to_ids[chars[index]]\n",
    "        if x == 4 or x == 8:  # ê, ơ\n",
    "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
    "            # for index2 in nguyen_am_index:\n",
    "            #     if index2 != index:\n",
    "            #         x, y = nguyen_am_to_ids[chars[index]]\n",
    "            #         chars[index2] = bang_nguyen_am[x][0]\n",
    "            return ''.join(chars)\n",
    "\n",
    "    if len(nguyen_am_index) == 2:\n",
    "        if nguyen_am_index[-1] == len(chars) - 1:\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            # chars[nguyen_am_index[1]] = bang_nguyen_am[x][0]\n",
    "        else:\n",
    "            # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "            # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "            x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "            chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "    else:\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "        # chars[nguyen_am_index[0]] = bang_nguyen_am[x][0]\n",
    "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "        # x, y = nguyen_am_to_ids[chars[nguyen_am_index[2]]]\n",
    "        # chars[nguyen_am_index[2]] = bang_nguyen_am[x][0]\n",
    "    return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
    "    \"\"\"\n",
    "        Chuyển câu tiếng việt về chuẩn gõ dấu kiểu cũ.\n",
    "        :param sentence:\n",
    "        :return:\n",
    "    \"\"\"\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    for index, word in enumerate(words):\n",
    "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
    "        if len(cw) == 3:\n",
    "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
    "        words[index] = ''.join(cw)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(txt):\n",
    "    return re.sub(r'<[^>]*>', '', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_from_file(folder_path):\n",
    "    inputFiles = os.listdir(folder_path)\n",
    "    for inputFile in inputFiles:\n",
    "        inputFileWasReplaced = inputFile.replace(inputFile[-11:], '')\n",
    "        inputFileWasReplaced = inputFileWasReplaced.replace(inputFileWasReplaced[:9], '')\n",
    "        with open('output' + '/' + inputFile, 'r', encoding='utf-8') as file:\n",
    "            for text in file.readlines():\n",
    "                if re.match('Title(.*)', text):\n",
    "                    continue\n",
    "                if text == '\\n':\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # Loại bỏ dữ liệu trùng lặp\n",
    "                cleaned_text = remove_duplicates(text)\n",
    "\n",
    "                # Loại bỏ các thẻ HTML\n",
    "                cleaned_text = remove_html_tags(cleaned_text)\n",
    "\n",
    "                # Loại bỏ các thẻ code, mã JavaScript và mã CSS\n",
    "                cleaned_text = remove_code(cleaned_text)\n",
    "\n",
    "                cleaned_text = convert_unicode(cleaned_text)\n",
    "\n",
    "                cleaned_text = ViTokenizer.tokenize(cleaned_text)\n",
    "\n",
    "                cleaned_text = cleaned_text.lower()\n",
    "\n",
    "                # Loại bỏ lỗi font hoặc các ký tự không mong muốn khác, nhưng giữ lại \"__label\"\n",
    "                cleaned_text = remove_special_characters(cleaned_text)\n",
    "\n",
    "                # Loại bỏ dữ liệu trong các dấu ngoặc nhọn {{...}}\n",
    "                cleaned_text = remove_curly_braces_content(cleaned_text)\n",
    "\n",
    "                cleaned_text = remove_startswith_or_endswith_underscore_except_label(cleaned_text, inputFileWasReplaced)\n",
    "\n",
    "                cleaned_text = format_content(cleaned_text, inputFileWasReplaced)\n",
    "\n",
    "                # Ghi dữ liệu đã được làm sạch vào tập tin mới\n",
    "                result_directory = 'result'\n",
    "                if not os.path.exists(result_directory):\n",
    "                    os.makedirs(result_directory)\n",
    "                output_file = os.path.join(result_directory, inputFileWasReplaced + '.txt')\n",
    "                with open(output_file, 'a', encoding='utf-8') as file:\n",
    "                    file.write(cleaned_text)\n",
    "        remove_stopwords(output_file, inputFileWasReplaced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = 'output'\n",
    "clean_text_from_file(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('stopwords.txt', 'r', encoding='utf-8') as stop_file:\n",
    "#     stopwords = set(stop_file.read().splitlines())\n",
    "# with open('result/chính_phủ.txt', 'r', encoding='utf-8') as input_file:\n",
    "#     for line in input_file:\n",
    "#         # tách các từ trong dòng và kiểm tra xem chúng có trong stopwords không\n",
    "#         words = line.split()\n",
    "#         print([word for word in words if word.lower() in stopwords])\n",
    "#         words = [word for word in words if word.lower() not in stopwords]\n",
    "\n",
    "# result_directory = 'result'\n",
    "# if not os.path.exists(result_directory):\n",
    "#     os.makedirs(result_directory)\n",
    "# output_file = os.path.join(result_directory, 'chính_phủ' + '.txt')\n",
    "# remove_stopwords(output_file, 'chính_phủ')\n",
    "\n",
    "# stopwords = ['thông']\n",
    "# paragraph = 'thông cáo thông_tin thông_báo'\n",
    "\n",
    "# words = paragraph.split()\n",
    "# for word in words:\n",
    "#     if word.lower() in stopwords:\n",
    "#         print(word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
